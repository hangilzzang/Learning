{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "간단하게 집고넘어가는 선형회귀이다"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://wikidocs.net/53560\n",
    "1. 가설수립: feature를 받아서 y를 예측하는 과정에 있어서 그 방법론들을 말하는것같다 이번에 써볼것은 선형회귀이다\n",
    "2. 비용함수: 실제 예측값과 오차를 계산하는 함수이다 loss function 즉 손실함수라고도 많이 불리는것같다 mse를 사용하셨는데 모든 오차를 제곱한다음에 평균을 구하는 방식이다 그러면 아무리봐도 제곱평균오차가 맞는것같다....\n",
    "3. 옵티마이저 - 경사 하강법(Gradient Descent): 경사하강법은 가장 기초적인 최적화 알고리즘이라고 한다  비용함수를 미분하여 접선의 기울기기가 낮은 방향으로 w및 b(선형회귀)값을 변경하는것이다 여기서 궁금증은 기울기가 0인지점이 여러개 있을경우 어떻게 되는지인데 이것은 후에 더 자세하게 알아보자 지금은 원활한 대회참여를 위한 제대로된 파이토치 공부가 급하다(너무늦은감이 있긴하지만 이제서야 필요성을 느낀것같다)\n",
    "4. 학습률이란 경사하강법으로 최적인 w,b값을 찾는 과정에서 얼마나 큰폭으로 이동할건지를 의미 너무 크면 제대로된값을 찾을수없다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dodo7\\miniconda3\\envs\\lesa4\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2135a8bb590>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 현재 실습하고 있는 파이썬 코드를 재실행해도 다음에도 같은 결과가 나오도록 랜덤 시드(random seed)를 줍니다.\n",
    "torch.manual_seed(2023) # 딥러닝에서 random num을 사용하는경우가 많다라고함"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "변수선언(이제 시작이다)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.FloatTensor([[1], [2], [3]])\n",
    "y_train = torch.FloatTensor([[2], [4], [6]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "가중치와 편향의 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# 가중치 W를 0으로 초기화하고 학습을 통해 값이 변경되는 변수임을 명시함.\n",
    "W = torch.zeros(1, requires_grad=True) \n",
    "# 가중치 W를 출력\n",
    "print(W) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "b = torch.zeros(1, requires_grad=True)\n",
    "print(b)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "지금 상태에서는 어떤 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lesa4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0d68ed8ea0a1c393350fa1234c971630b1febd64e890ef6951eed245e2291709"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
